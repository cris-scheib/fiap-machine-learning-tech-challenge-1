# API de Livros - FIAP Machine Learning Tech Challenge 1

Projeto de extra√ß√£o e API p√∫blica para consulta de livros, integrando web scraping e FastAPI.

| ![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg) ![FastAPI](https://img.shields.io/badge/framework-FastAPI-009688?logo=fastapi) ![MIT License](https://img.shields.io/badge/license-MIT-yellow.svg) |
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|

-----------------------------------

## Sum√°rio

- [Descri√ß√£o](#descri√ß√£o)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Arquitetura](#arquitetura)
- [Como Utilizar](#como-utilizar)
- [Endpoints](#endpoints)
- [Licen√ßa, Autores e Agradecimentos](#licen√ßa-autores)

-----------------------------------

## Descri√ß√£o

O objetivo deste projeto √© expor uma **API RESTful** para facilitar o acesso aos dados de diversos livros. Esses dados originalmente s√£o extra√≠dos via **web scraping** do site [Books to Scrape](https://books.toscrape.com/) 

Os dados dispon√≠veis envolvem informa√ß√µes sobre:

- `Id`: Identificador do livro
- `T√≠tulo`: T√≠tulo do livro
- `Pre√ßo`: Pre√ßo do livro
- `Disponibilidade`: Status da disponibilidade do livro
- `Avalia√ß√£o`: Avalia√ß√£o do livro em estrelas
- `Categoria`: Categoria do livro
- `Imagem`: Link da imagem do livro


-----------------------------------

## Tecnologias Utilizadas

- **Python 3.11**
- **FastAPI**
- **Uvicorn**
- **BeautifulSoup4**
- **SQLite**

-----------------------------------

## Arquitetura

O projeto segue uma arquitetura em camadas, inspirada no Clean Architecture,
separando responsabilidades em diferentes m√≥dulos e 
facilitando manuten√ß√£o e testes.

### üìÇ Estrutura do Reposit√≥rio

```
fiap-machine-learning-tech-challenge-1/
‚îú‚îÄ‚îÄ api/                         # Aplica√ß√£o FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Entrypoint (uvicorn app.main:app)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # Depend√™ncias da API
‚îÇ   ‚îî‚îÄ‚îÄ app/                     # C√≥digo-fonte da API
‚îÇ       ‚îú‚îÄ‚îÄ controllers/         # Implementa√ß√£o dos endpoints (routes)
‚îÇ       ‚îú‚îÄ‚îÄ core/                # Configura√ß√µes de autentica√ß√£o e sess√£o de BD
‚îÇ       ‚îú‚îÄ‚îÄ models/              # Modelos SQLAlchemy
‚îÇ       ‚îú‚îÄ‚îÄ schemas/             # Schemas Pydantic (request/response)
‚îÇ       ‚îî‚îÄ‚îÄ services/            # L√≥gica de neg√≥cio e componente de scraping
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias gerais do projeto
‚îú‚îÄ‚îÄ runtime.txt                  # Vers√£o do runtime (deploy)
‚îî‚îÄ‚îÄ vercel.json                  # Configura√ß√µes de deploy
```

### Descri√ß√£o das camadas:

**controllers**: Define os pontos de entrada da API (endpoints) e realiza roteamento.

**services**: Implementa a l√≥gica de neg√≥cio, orquestrando opera√ß√µes de scraping e acesso a dados via models.

**models**: Representa o dom√≠nio de dados, definindo entidades e mapeamentos com SQLAlchemy.

**schemas**: Cont√©m os Pydantic models para valida√ß√£o e serializa√ß√£o de requisi√ß√µes e respostas.

**core**: Agrupa configura√ß√µes centrais, como autentica√ß√£o JWT, inicializa√ß√£o de sess√£o de banco de dados e configura√ß√µes gerais.

Essa separa√ß√£o melhora a modularidade, favorece testes unit√°rios e permite evoluir cada camada independentemente.

-----------------------------------

## Como Utilizar

Voc√™ pode usar a API de duas formas: **localmente** no seu ambiente de desenvolvimento ou 
consumindo a **vers√£o j√° deployada**.

Para sua conveni√™ncia, o reposit√≥rio j√° inclui um banco de dados (`.sqlite`) e um arquivo (`.csv`) 
com os dados atualizados obtidos via Web Scraping previamente, al√©m de um usu√°rio de testes j√° criado. 
Isso permite que voc√™ teste a API imediatamente com uma base de dados de cerca de mil livros, sem precisar executar o Web Scraping.

**Autentica√ß√£o (v√°lido para ambos os modos)**

Cadastre um usu√°rio (ou utilize o de teste)

Usu√°rio de teste:

    username: test_user  
    password: test12345

N√£o se esque√ßa de gerar e usar o token JWT antes de acessar os dados.

### ‚òÅÔ∏è Via Deploy (produ√ß√£o)

Acesse a vers√£o p√∫blica em: https://fiap-machine-learning-tech-challeng-taupe.vercel.app/api/docs 

L√° voc√™ ter√° o Swagger UI e poder√° testar todos os endpoints diretamente no navegador.

### üè† Execu√ß√£o Local

### Pr√©-requisitos

- Git
- Python 3.11+

### Passos

1. **Clone o reposit√≥rio**
   ```bash
   git clone https://github.com/cris-scheib/fiap-machine-learning-tech-challenge-1.git
   cd fiap-machine-learning-tech-challenge-1
   ```
2. **Crie e ative um ambiente virtual**
   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/macOS
   venv\Scripts\activate    # Windows
   ```
3. **Instale depend√™ncias gerais**
   ```bash
   pip install -r requirements.txt
   ```
4. **Inicie a API**
   ```bash
   cd api
   uvicorn main:app --reload
   ```
5. **Execute o Scraping (Opcional)**

    > **Aten√ß√£o:** O processo de Web Scraping √© demorado, levando mais de 30 minutos. 
    > **Ele n√£o √© necess√°rio para iniciar a API**, a menos que voc√™ queira gerar os dados do zero,e **antes de sua
    execu√ß√£o certifique-se de criar ou ter um usu√°rio criado**.

   ```bash
   cd api
   python -m app.services.scrapper.scrapper_service
   ```

A API estar√° dispon√≠vel em `http://127.0.0.1:8000`. 

A documenta√ß√£o interativa √© acess√≠vel em `http://127.0.0.1:8000/docs` (Swagger UI) 
e `http://127.0.0.1:8000/redoc` (ReDoc).

## Endpoints

### Autentica√ß√£o (opcional)

#### `POST /api/v1/auth/login`
- **Descri√ß√£o:** Gera um token JWT para acesso a rotas protegidas.
- **Body Request:**
  ```json
  { "username": "seu_usuario", "password": "sua_senha" }
  ```
- **Resposta (200):**
  ```json
  { "access_token": "<seu_token>", "token_type": "bearer" }
  ```

Inclua no header das requisi√ß√µes protegidas:
```
Authorization: Bearer <seu_token>
```

---

### `GET /api/v1/health`
- **Descri√ß√£o:** Verifica se a API est√° no ar.
- **Resposta (200):**
  ```json
  { "status": "ok" }
  ```

---

### `GET /api/v1/books`
- **Descri√ß√£o:** Lista todos os livros carregados.
- **Resposta (200):**
  ```json
  [
    { "id": 1, "title": "A Light in the Attic", "price": 51.77, "category": "Travel", "availability": "In stock", "rating": 3 },
    ...
  ]
  ```

---

### `GET /api/v1/books/{id}`
- **Descri√ß√£o:** Obt√©m detalhes completos de um livro pelo seu ID.
- **Path Param:**
  - `id` (int)
- **Resposta (200):**
  ```json
  { "id": 1, "title": "A Light in the Attic", "price": 51.77, "category": "Travel", "availability": "In stock", "rating": 3, "description": "Descri√ß√£o detalhada..." }
  ```
- **Resposta (404):**
  ```json
  { "detail": "Book not found" }
  ```

---

### `GET /api/v1/books/search`
- **Descri√ß√£o:** Busca livros por t√≠tulo parcial e/ou categoria.
- **Query Params:**
  - `title` (string, opcional)
  - `category` (string, opcional)
- **Resposta (200):** Lista de livros que atendem aos filtros.

---

### `GET /api/v1/categories`
- **Descri√ß√£o:** Retorna todas as categorias existentes.
- **Resposta (200):**
  ```json
  ["Travel", "Mystery", "Historical Fiction", ...]
  ```

## Licen√ßa, Autores

### üßë‚Äçüíª Desenvolvido por

- `Beatriz Rosa Carneiro Gomes - RM365967`
- `Cristine Scheibler - RM365433`
- `Guilherme Fernandes Dellatin - RM365508`
- `Iana Alexandre Neri - RM360484`
- `Jo√£o Lucas Oliveira Hilario - RM366185`

Este projeto √© apenas para fins educacionais e segue a licen√ßa MIT.


---------------- Lembrete para remover abaixo ----------------
### Features

- **Complete Data Extraction**: Title, price, rating, availability, category, image URL
- **Robust Error Handling**: Retry logic and comprehensive logging
- **Respectful Scraping**: Configurable delays and rate limiting
- **Pagination Support**: Automatically handles multi-page categories
- **Data Quality**: Text cleaning and normalization

### Output

The scraper creates a CSV file in the `data/` directory with the following columns:
- `title`: Book title
- `price`: Numeric price value
- `rating`: Star rating (One, Two, Three, Four, Five)
- `availability`: Availability status
- `category`: Book category
- `image_url`: Full URL to the book cover image
- `book_url`: URL to the book detail page

### Configuration

You can modify the following in `scripts/scrapper.py`:
- `DELAY_BETWEEN_REQUESTS`: Delay between requests (default: 1.0 seconds)
- `MAX_RETRIES`: Maximum retry attempts (default: 3)

## API <a name="api"></a>

### Quick Start

1. Create and activate a Python virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# or
venv\Scripts\activate  # Windows
```

2. Install dependencies:
```bash
# Option 1: Using pip directly
pip install -r requirements.txt

# Option 2: Using the installation script
python install_dependencies.py
```

> **Note**: If you encounter import errors, make sure to run the installation script to properly install all dependencies.

3. Run the script to start the server:
```bash
# Option 1: Standard startup
python start_server.py

# Option 2: Startup with dependency checks (recommended if you have import errors)
python start_server_with_checks.py
```

4. Or navigate to the API directory and run:
```bash
cd api
uvicorn main:app --reload
```

### Available Endpoints

- `GET /api/v1/books`: List all books
- `GET /api/v1/books/search?title=&category=`: Search books by title and category
- `GET /api/v1/books/{id}`: Get a book by ID

### Endpoint GET /api/v1/books/{id}

This endpoint returns the details of a specific book by its ID.

**Example Response (Book found):**
```json
{
  "id": 1,
  "title": "A Light in the Attic",
  "price": 51.77,
  "availability": "In stock",
  "rating": "Three",
  "category": "Poetry"
}
```

**Example Response (Book not found):**
```json
{
  "detail": "Error Book not found."
}
```

### Compatibility Issues

If you encounter compatibility issues when running the API, try:

1. Using Python 3.9 or 3.10 instead of newer versions
2. Running the `simulate_endpoint.py` script to test functionality without starting the server
3. Checking if the dependency versions in `requirements.txt` are compatible with your Python version

## Project Structure <a name="structure"></a>

```
fiap-machine-learning-tech-challenge-1/
‚îú‚îÄ‚îÄ api/                    # REST API application
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/    # API controllers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/          # Core functionality (auth, database)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/        # Data models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/       # Pydantic schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/      # Business logic
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # FastAPI application entry point
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt   # API dependencies
‚îú‚îÄ‚îÄ scripts/               # Web scraping tools
‚îÇ   ‚îú‚îÄ‚îÄ scrapper.py        # Main scraper script
‚îÇ   ‚îú‚îÄ‚îÄ demo_scrapper.py   # Demo version for testing
‚îÇ   ‚îú‚îÄ‚îÄ test_scrapper.py   # Test script
‚îÇ   ‚îú‚îÄ‚îÄ utils.py           # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt   # Scraper dependencies
‚îÇ   ‚îú‚îÄ‚îÄ run_scrapper.bat   # Windows batch file
‚îÇ   ‚îî‚îÄ‚îÄ README.md          # Scraper documentation
‚îú‚îÄ‚îÄ data/                  # Output directory for scraped data
‚îî‚îÄ‚îÄ README.md              # This file
```

![image]()

## Troubleshooting

### Import Errors

If you encounter import errors like `Unable to import 'fastapi'` or `Unable to import 'sqlalchemy'`, follow these steps:

1. Make sure you have activated your virtual environment
2. Run the environment check script to diagnose and fix issues:
   ```bash
   python check_environment.py
   ```
   This script will check your Python version, installed dependencies, and project structure, and offer to install any missing dependencies.

3. Alternatively, run the installation script to install all dependencies:
   ```bash
   python install_dependencies.py
   ```

4. If the issue persists, try installing the dependencies manually:
   ```bash
   pip install fastapi==0.95.2 uvicorn==0.22.0 pydantic==1.10.8 sqlalchemy==1.4.48 beautifulsoup4==4.12.2 requests==2.31.0
   ```

## Compatibility Issues

This project was developed and tested with Python 3.8+. Some compatibility issues may occur with older versions.

## Licensing, Authors and Acknowledgments<a name="licensing"></a>
